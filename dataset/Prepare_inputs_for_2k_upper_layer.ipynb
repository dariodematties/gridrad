{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db622ac-edfa-45c1-bce3-bc642f9e78a8",
   "metadata": {},
   "source": [
    "# Prepare inputs for 2k upper layer in the hierarchy\n",
    "\n",
    "This notebook prepares the input for the next layer in the hierarchy.\n",
    "\n",
    "I basically generates a `.pt` file per each element in the features from the `output_features.pf` file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85387fe-b40f-4ab0-b338-2f576ce23403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d328420b-8982-4264-9792-8c347452ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features generated from the first layer in the hierarchy\n",
    "output_features_paht = '/path/to/your/data/SATELLITE/output_inference/output_features.pt'\n",
    "features = torch.load(output_features_paht)\n",
    "# output_dir is the path pointing to the folder in which the files will be saved\n",
    "# These files will be used for training the next layer in the hierarchy\n",
    "output_dir = '/path/to/your/data/SATELLITE/input_2k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2af58a-29f8-4e5d-9e7d-9c2180f418c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just inspect on element of features (replace 'crop_30_0.pt' with an appropriate feature name)\n",
    "features['crop_30_0.pt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee6ee1-e774-49bc-bedb-664732601cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is the loop that generates the individual files per each element in features\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "for i, (file_name, embedding) in enumerate(features.items()):\n",
    "    print(i)\n",
    "    print(file_name)\n",
    "    print(embedding.shape)\n",
    "    torch.save(embedding, os.path.join(output_dir, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550bb72-4934-4206-b5e7-674d6619d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I am inspecting the output\n",
    "input_tensor = torch.load('/path/to/your/data/SATELLITE/input_2k/crop_30_0.pt')\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd150ba-4b70-4d98-a58d-46decd2e04dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is the number of elements inside features\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f4299-89fe-4691-ab6b-282d3c704116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gridrad",
   "language": "python",
   "name": "gridrad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
